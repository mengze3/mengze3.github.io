---
layout: archive
title: "Transformer
-
based Trajectory Planning for Robots: Extending to UAVs and UGVs"
permalink: /car/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

<head>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>
        .container {
            display: flex; /* Use Flexbox for layout */
            align-items: start; /* Align items at the start of the container */
        }
        .video {
            width: 50%; /* Assign 50% width for the video */
            padding-right: 10px; /* Add some space between video and text */
        }
        .text {
            width: 50%; /* Assign 50% width for the text */
        }
      .center {
            text-align: center;
        }
        iframe {
            width: 100%; /* Make the video responsive */
            height: 300px; /* Set a fixed height for the video */
        }
        .flex-container {
            display: flex;
        }
    </style>
</head>

   
<body>





	
    <h1>Contributions</h1>
    <p>• We propose a lightweight two-stage neural network that is capable of learning a path connecting the start and goal SE(2) states directly from the environment. 
      A salient feature of our algorithm is its independence from tradi-tional sampling or search algorithms, which significantly enhances time efficiency and temporal stability. 
      Further-more, our network is adept at learning the paradigms of ground truth trajectories, thereby providing superior initial path for optimization. 
      This capability significantly reduces the back-end computational load and required optimization time.</p>
  
    <p>• We devise a distinctive trajectory formulation character-ized by a dual-layer, piece-wise polynomial architecture, 
      upon which we construct a differential flatness-based spatial-temporal joint trajectory optimization formulation. 
      This methodology is adept at not only facilitating the efficient generation of superior, collision-free trajectories but also at addressing the intrinsic ambiguities associated with flatness models, 
      thus augmenting the completeness. Furthermore, we meticulously derive the gradient propa-gation chain within this trajectory representation, 
      which empowers the proficient employment of gradient-based numerical optimization techniques.</p>

    <p>• We amalgamate the proposed front-end and back-end components to present a high-quality vehicle trajectory planner. Moreover, 
      we employ an iterative modal plan-ning algorithm to efficaciously mitigate the transitions between forward and reverse motions during vehicle ma-neuvering. 
      Additionally, we conduct a series of ablation studies to meticulously analyze the contribution of each component, 
      and comparative experiments are undertaken to validate the superiority of our algorithm.</p>
  
    <!-- 大标题 -->
    <h1>LEARNING-BASED PATH PLANNING</h1>

  <p>
In this section, we introduce the learning-based path planner that leverages the performance of the network to directly output an initial path for optimization without the need for additional sampling or searching. 
      Our path planner takes as input the navigation start ${x}^p_i$ and goal ${x}^p_N$, 
      as well as the grid-based environment $\mathcal{E}$ of size $H*W$, and directly outputs a path $ {\mathrm{p}} =
    \{ {x}^p_1,...,{x}^p_i,...,{x}^p_N\} $ serialized as a sequence of multiple state points.
    Here, the resolution of each grid is defined as $r_s$. Moreover, each state point  in the path is associated with the $\mathbb{SE}(2)$ state of the robot, which includes its position and orientation angle.
    We firstly describe the network architecture, which initially estimates the distribution of each state point in the environmental space, 
      and then further reduces their uncertainty to determine the precise states of the points in the sequence. Then, we  discuss the loss function used during training, 
      which includes supervising the network's output with the ground truth  and penalizing  infeasible paths based on safety considerations and nonholonomic dynamic constraints.</p>
  
    
   <h2>A. Neural Network Architecture</h2>
    
  <div class="center">
      <img  width="1040" height="680" src="https://github.com/mengze3/mengze3.github.io/blob/c5ee3b2ab134c71729fdb51c8c76b3df9e1ae025/_pages/model2.png?raw=true" alt="">
  </div>
   
  <p>Our network comprises three main components: the feature extraction layer, the global distribution layer, and the local correction layer, as illustrated in Fig. \ref{fig:network}.
	In practice, directly localizing the position of a specific state point within the environment is challenging and labor-intensive. Therefore, drawing inspiration from the R-CNN, our network follows a two-stage inference architecture.
	Initially, we uniformly partition $\mathcal{E}$ into $H_l * W_l$ region proposals, where each region proposal corresponds to a block of size $\frac{H}{H_l} * \frac{W}{W_l}$ in the environment. The center point of each region proposal is designated as an anchor point.
	Subsequently, we employ the global distribution layer to obtain the probability distribution of each state point with respect to the region proposals. This step involves estimating the coarse spatial distribution of the point. Next, leveraging the local correction layer, we further obtain the accurate position of the state point based on the environmental features and the probability distribution obtained earlier.
	Intuitively, our aim is to first approximately determine the region proposal in which each state point resides and then regress its positional offset relative to the anchor, thereby recovering the global position of the point.</p>

	<p>The input to our network consists of the environment $\mathcal{E}$, the encoding of the start and goal states. Here, 
	$\mathcal{E}$ is represented by a Euclidean Signed Distance Field (ESDF), where each element represents the signed distance from obstacles at that location.
	We adopt a start-goal encoding strategy by highlighting patches of size $c*c$ on a tensor of size $H*W$. Specifically, we assign a value of -1 to the patch representing the start point and a value of 1 to the patch representing the goal point. The remaining positions in the tensor are set as $0$.
	To fully represent the $\mathbb{SE}(2)$ space, we introduce two additional $H*W$ tensors to capture the cosine and sine values of the robot orientations at the start and goal locations.
	Specifically, one tensor represents the cosine values for the patches corresponding to the starting and target points, while the other tensor represents the sine values.
	Subsequently, the aforementioned representations of the environment and the start and goal $\mathbb{SE}(2)$ states are concatenated to form a $4*H*W$ tensor, which serves as the input to the feature extraction layer of our model. The feature extraction layer consists of a Fully Convolutional Network (FCN) and a Transformer Encoder ~\cite{vaswani2017attention}. The FCN encodes path plan problem into a high-dimensional latent space, and the size of this latent feature is downsampled to $d*H_l*W_l$ to match the shape of the probability distribution of region proposals. Here, $d$ represents the user-defined dimension of the latent features. Next, we apply the transformer module to further fuse the features within the latent space, without altering the shape of the feature tensor. For brevity, we denote the output of the feature extraction layer as $\mathcal{M}$.
	$\mathcal{M}$ is further inputted to the global distribution layer, resulting in the probability distribution map $\mathcal{P}$ over the region proposals for $N$ points along the path, with a size of $N*H_l*W_l$. 
	Here, we denote the probability of the $i$-th point belonging to the $(j,k)$-th  region as $\varrho_{i,j,k}$. Moreover, it is evident that these probabilities should satisfy the principle of probability normalization:
	\begin{align}
	\sum_{j=0}^{H_l-1}\sum_{k=0}^{W_l-1}\varrho_{i,j,k}=1,\forall i \in \{1,... ,N\}.
	\end{align}</p>

	<p>The probability distribution $\mathcal{P}$ and latent features $\mathcal{M}$ are concatenated and fed  into the local correction layer, which outputs a tensor $\mathcal{O}$ of size $3N*H_l*W_l$. 
	The physical meaning of this tensor $\mathcal{O}$ is to assign an orientation angle 
	$b^{\theta}_{i,j,k}$ and positional offsets $(b^x_{i,j,k}, b^y_{i,j,k})$ relative to the anchor for each region. 
	Instinctively, we consider selecting the region with the highest probability from $\mathcal{P}$ and retrieving the corresponding positional offset and orientation angle from $\mathcal{O}$ to accurately recover the $\mathbb{SE}$(2) state of any point along the path. 
		However, the operation of selecting the region with the highest probability is non-differentiable, posing challenges for training. Consequently, we employ a weighted summation based on $\mathcal{P}$ to compute the state of any point, enabling differentiability and facilitating effective training:
	\begin{align}
	r^p_{x,i} &= \hat{r}^p_{x,i} + \widetilde{r}^p_{x,i}, \\
	\hat{r}^p_{x,i} &= \sum_{j=0}^{H_l-1}\sum_{k=0}^{W_l-1}\varrho_{i,j,k}(j+0.5)r_s, \widetilde{r}^p_{x,i} = \sum_{j=0}^{H_l-1}\sum_{k=0}^{W_l-1}\varrho_{i,j,k}b^x_{i,j,k},\nonumber\\
	r^p_{y,i} &= \hat{r}^p_{y,i} + \widetilde{r}^p_{y,i},\\
	\hat{r}^p_{y,i}&=\sum_{j=0}^{H_l-1}\sum_{k=0}^{W_l-1}\varrho_{i,j,k}(k+0.5)r_s, \widetilde{r}^p_{y,i} = 
	\sum_{j=0}^{H_l-1}\sum_{k=0}^{W_l-1}\varrho_{i,j,k}b^y_{i,j,k},\nonumber\\
	\theta^p_{i} &=  \sum_{j=0}^{H_l-1}\sum_{k=0}^{W_l-1}\varrho_{i,j,k}b^\theta_{i,j,k},\forall i \in\{1,...,N\},
	\end{align}
	where $r^p_{x,i}, r^p_{y,i}$, and $\theta^p_{i}$ represent the position and orientation angle of the $i$-th state point, respectively. 
	$\hat{r}^p_{x,i}$ and $\hat{r}^p_{y,i}$ represent the weighted sum of anchor positions based on the probability distribution $\mathcal{P}$, 
	which can also be regarded as the output of the global distribution layer. For the sake of simplicity, we define the rough path composed of  $(\hat{r}^p_{x,i}, \hat{r}^p_{y,i})$ as $\hat{ {\mathrm{P}}}$. 
	On the other hand,  $\widetilde{r}^p_{x,i}$ and $ \widetilde{r}^p_{y,i}$ refer to the weighted sum of positional offsets based on  $\mathcal{P}$,  
	which aims to correct $\hat{ {\mathrm{P}}}$ and enhance its overall quality.</p>

	
	<p>Moreover, in order to mitigate outliers and increase smoothness, we employ a sliding window for mean filtering along the aforementioned path.
	$(\hat{r}^p_{x,i}, \hat{r}^p_{y,i})$
	$(\widetilde{r}^p_{x,i}, \widetilde{r}^p_{y,i})$
	$({r}^p_{x,i}, {r}^p_{y,i})$
	Next, we provide the implementation details of each major part of the network.</p>	

	
     
  <p>1) Feature Extraction: In this component, the FCN consists of four dual-convolution layers. The first dual-convolution layer does not alter the width and height of the tensor, but only increases the number of channels. 
    The subsequent three dual-convolution layers downsample the tensor in width and height, while doubling the number of channels after each layer.	Moreover, 
    MaxPool is employed for downsampling, and ReLU and Batch Normalization are nested between convolutions to enhance the generalization performance.	Then, 
    the output of the FCN is reshaped row-wise into a size of $d*(H_lW_l)$ and undergoes positional encoding before being fed into the Transformer Encoder. 
    The Transformer module further learns the relationships between these latent features through multi-headed self-attention and multilayer perceptron blocks.</p>

  <p>2) Global Distribution: This module predicts the probability distribution of N state points in the downsampled space, hence the output tensor dimension should be $N * H_l * W_l$.
	For this purpose, we efficiently implement this operation using two layers of $3*3$ padding convolutions. Additionally, we perform Softmax  on each channel of the output tensor to ensure proper  probability normalization.</p>

  <p>3) Local Correction: Similar to the previous module, we employ two layers of $3*3$ padding convolutions to assign the orientation angle and position offsets relative to the anchor for each  region. 
    The output tensor has dimensions of $3N * H_l * W_l$. Furthermore, 
    we apply the Sigmoid activation function to limit the position offsets of the network output, ensuring that the corrected point remains in the vicinity of the anchor. </p>
  

   <h2>B. Loss Function</h2>
  
      <p>Anchor Point Classification Loss. We model the role of the global distribution layer as a multi-classification problem, where our objective is to maximize the probability of the region containing the ground truth point.
	We apply the cross-entropy loss  to measure the discrepancy between the predicted region hypotheses and the ground truth:
	\begin{align}
		\mathcal{L}_{ce} = - w_{ce}\sum_{i=1}^{N}\sum_{j=0}^{H_l-1} \sum_{k=0}^{W_l-1}\overline\varrho_{i,j,k} \log(\varrho_{i,j,k}).
	\end{align}
	where $\overline\varrho_{i,j,k}$ represents the probability ground truth.</p>
	
	       <p>Path Supervision Loss. We employ the Mean Square Error (MSE)  loss to supervise the $\mathbb{SE}$(2) state for each point along the path:
	\begin{align}
	&	\mathcal{L}_{mse} = w_{p}\frac{ \sum_{i=1}^{N} (r^p_{x,i}-\overline r^p_{x,i})^2+(r^p_{y,i}-\overline r^p_{y,i})^2}{2N} \nonumber\\
		&+w_{\theta}\frac{ \sum_{i=1}^{N} (\cos\theta^p_{i}-\cos\overline\theta^p_{i})^2+(\sin\theta^p_{i} -\sin\overline\theta^p_{i})^2}{2N},
	\end{align}
	where $(\overline r^p_{x,i}, \overline r^p_{y,i},\overline \theta^p_{i})$ is the $\mathbb{SE}$(2) state of the ground truth.
	Furthermore, to address potential periodicity issues with angles, we supervise the sine and cosine values of the angles instead of the angles themselves.</p>

       <p>Smoothness Loss. In this part, we characterize smoothness by considering the path length and the total change in angle. Moreover, when $N$ is sufficiently large, the difference between adjacent state points is small. Hence, to mitigate periodicity, we reasonably substitute the difference between the sines and cosines of angles for the angle difference. To emphasize the refinement of suboptimal cases where the planned path lacks smoothness compared to the ground truth, we design the following loss function to penalize such deviations:
	\begin{align}
	&\mathcal{L}_{smo} = w_{arc} (\mathrm{ReLU}(\frac{\sum_{i=1}^{N-1} 
	\Delta^p_{r,i}
	}{\sum_{i=1}^{N-1} 
	\overline\Delta^p_{r,i}}-1))^2\nonumber\\
	 &\ \ \ \ \ \ +w_{rsm} (\mathrm{ReLU}(\frac{\sum_{i=1}^{N-1} 
	 \Delta^p_{\theta,i}
	 }{\sum_{i=1}^{N-1} 
	 	 \overline\Delta^p_{\theta,i}}-1))^2,
	 \\
	&\Delta^p_{x,i} = r^p_{x,i}-r^p_{x,i+1},\Delta^p_{y,i} = r^p_{y,i}-r^p_{y,i+1},\nonumber\\
	&\Delta^p_{c,i} = \cos\theta^p_{i}-\cos\theta^p_{i+1},\Delta^p_{s,i} = \sin\theta^p_{i}-\sin\theta^p_{i+1},\nonumber\\
	&\Delta^p_{r,i} = \sqrt{(\Delta^p_{x,i})^2+(\Delta^p_{y,i})^2},
	\Delta^p_{\theta,i} = \sqrt{(\Delta^p_{c,i})^2+(\Delta^p_{s,i})^2}\nonumber,
	\end{align}
	where $\Delta^p_{*,i}$ and $\overline \Delta^p_{*,i}$ denote the $\mathbb{SE}$(2) state differences between adjacent points on the planned path and the ground truth, respectively.</p>

         <p>Nonholonomic Dynamic Loss. We design the following loss function to emphasize the alignment between the direction of the line connecting adjacent points and the orientation angle direction:
	\begin{align}
	&\mathcal{L}_{hol} = \frac{w_{hol}}{N-1} \sum_{i=1}^{N-1}
	\mathrm{ReLU}(
	([\Delta^p_{x,i},\Delta^p_{y,i}]
	\begin{bmatrix}
	-\sin\theta^p_{i+1} \\
	\cos\theta^p_{i+1}
	\end{bmatrix})^2-\delta_h),
	\end{align}where $\delta_h$ is the user-defined tolerance threshold.</p>

         <p>Curvature Constraint Loss. We define the following loss function to penalize exceeding the specified curvature threshold $\kappa_{max}$:
	\begin{align}
	&\mathcal{L}_{cur} = \frac{w_{cur}}{N-1} \sum_{i=1}^{N-1}
	(\mathrm{ReLU}(
	\Delta^p_{\theta,i}-\kappa_{max}*\Delta^p_{r,i}
	))^2,
	\end{align}</p>

          <p>Uniform Loss. In the spatial domain, our objective is to attain a highly uniform distribution of points, which is achieved by penalizing variance. Moreover, we further normalize this variance by the path length of the ground truth, thereby ensuring that the network does not excessively prioritize long-distance path planning problems.
	\begin{align}
	&\mathcal{L}_{uni} = \frac{w_{uni}}{(N-1)\sum_{i=1}^{N-1}\overline\Delta^p_{r,i}} \sum_{i=1}^{N-1}(
	\Delta^p_{r,i}-\frac{\sum_{j=1}^{N-1}\Delta^p_{r,j}}{N-1})^2,
	\end{align}</p>

          <p>Obstacle Avoidance Loss. We design the following loss function to emphasize the collision-free property of paths to the network:
	\begin{align}
		&	\mathcal{L}_{obs} = w_{obs}\frac{ \sum_{i=1}^{N} (\max(0,\delta _d-S_d( {x}^p_1,\mathscr{S})))^2}{N}, 
	\end{align}
	where $S_d$ represents the signed distance of the state point from obstacles, taking into account the shape of the robot denoted by $\mathscr{S}$.
	$\delta_d\in\mathbb{R}^+$ is the minimum safety distance from  obstacles set by the user.
	 The signed distance at any grid  can be obtained directly from the ESDF, and we utilize bilinear interpolation to smooth out the discontinuities caused arising from the discretization of space.$\sum_{o=1}^{4}\delta s_o$</p>


    <h1>GRADIENT-BASED TRAJECTORY OPTIMIZATION</h1>
  
    <p>In this section, we conduct spatial-temporal optimization on the rough path obtained in the previous section, taking into account a higher-dimensional and more accurate dynamic model, 
      while ensuring collision-free property. Firstly, we intro-duce the differential flatness model for car-like robots, which serves as a cornerstone for subsequent optimization modeling. Next, 
      we present the trajectory optimization formulation in the flat space. In comparison to our previous work, one significant distinction lies in the design of a dual-layer polynomial-based trajectory parameterization. 
      This approach inherits the efficient characteristics of the prior work while fundamentally addressing the singularity issues inherent in the flat model. 
      Finally, we discribe the gradient backpropagation computation process and practical solution details specific to this optimization formulation.</p>
  
    <h2>A. Differential Flatness-Based Vehicle Model</h2>

	<div class="center">
	<img  width="640" height="320" src="https://github.com/mengze3/mengze3.github.io/blob/6283c629a1581614069793aa089605617c92e3b5/_pages/car.png?raw=true" alt="">
	</div>


	
    <p>We employ the simplified kinematic bicycle model to depict a four-wheel vehicle. Under the assumption of front-wheel drive and flawless rolling with no slippage, the motion model is represented as illustrated in Fig.\ref{fig:difmodel}. 
	Here, we consider a more detailed and accurate dynamic model: $\left(p_x, p_y, \theta, v, a, \phi, \omega\right)^{\rm T}$,
	\begin{align}
	&\frac{d}{dt} \begin{bmatrix}
	p_x\\
	p_y\\
	\theta\\
	v\\
	\phi
	\end{bmatrix}= 
	\begin{bmatrix}
	v\cos\theta\\
	v\sin\theta\\
	v\tan\phi/L\\
	a\\
	\omega
	\end{bmatrix},
	\end{align}
	where $ {p} = \left(p_x, p_y\right)^{\rm T}$ denotes the position at the center of the rear wheels, $v$ is the longitudinal velocity w.r.t vehicle's body frame, 
	$a$ represents the longitude acceleration, $\phi$ is the steering angle of the front wheels,  $\omega$ is the steer angular velocity, and $L$ is the wheelbase. 
	Subsequently, we select the flat output $ {\sigma} := \left(\sigma_x, \sigma_y\right)^{\rm T}$, where $ {\sigma} =  {p}$ represents the position, notably centered on the rear wheel of the vehicle.
	For computational convenience, we  introduce an auxiliary antisymmetric matrix $ {{\rm B}} := \begin{bmatrix}
	0 & -1\\1 & 0\end{bmatrix} $ and the transformation of the remaining motion variables can be described as follows:
<!--     \begin{subequations} -->
	\begin{align}
		v     & =  \eta ||\dot{ {\sigma}}_{|t}||_2,  
		\theta    =   \arctan2(\eta\dot{\sigma}_{y|t}, \eta\dot{\sigma}_{x|t}), \label{eq:v0}\\
    	\end{align}
	    
    	\begin{align}
		a  & =  \eta\frac{\ddot{ {\sigma}}_{|t}^\mathrm{T}\dot{ {\sigma}}_{|t}}{||\dot{ {\sigma}}_{|t}||_2}\\
    	\end{align}

    	\begin{align}
		\phi   & =   \arctan\left(\eta\frac{\ddot{ {\sigma}}_{|t}^\mathrm{T}  {{\rm B}} \dot{ {\sigma}}_{|t}L   }{ {||\dot{ {\sigma}}_{|t}||}_2^3}\right),\label{eq:phi0}\\
	\end{align}

    	\begin{align}
	    	\omega &= \eta L \frac{  \dddot{ {\sigma}}_{|t}^\mathrm{T} {{\rm B}}\dot{ {\sigma}}_{|t}
	||\dot{ {\sigma}}_{|t}||_2^3-3\ddot{ {\sigma}}_{|t}^\mathrm{T} {{\rm B}}\dot{ {\sigma}}_{|t}\ddot{ {\sigma}}_{|t}^\mathrm{T}\dot{ {\sigma}}_{|t}||\dot{ {\sigma}}_{|t}||_2}{||\dot{ {\sigma}}_{|t}||_2^6+
	(\ddot{ {\sigma}}_{|t}^\mathrm{T} {{\rm B}}\dot{ {\sigma}}_{|t}L)^2}.\label{eq:omega0}\\
	\end{align}
<!-- \end{subequations} -->
	    
	$\dot{ {\sigma}}_{|t}, \ddot{ {\sigma}}_{|t}$ and $ \dddot{ {\sigma}}_{|t}$
	are the  first, second, and third derivatives of the flat output w.r.t time, respectively.
	$\eta \in \{-1, 1\}$ is an additional variable fixed in optimization to characterize the motion direction of the vehicle, where $\eta = -1$ and $\eta = 1 $ represent the backward and forward movements, respectively.
	Hence, leveraging the inherent differential flatness property, we can employ the flat outputs and their finite derivatives to represent various state variables of the robot, thereby streamlining trajectory planning and enhancing optimization processes.</p>

      <h2>B. Dual-Layer Polynomial-Based Optimization Formulation</h2>


	<div class="center">
	<img  width="640" height="320" src="https://github.com/mengze3/mengze3.github.io/blob/6283c629a1581614069793aa089605617c92e3b5/_pages/transition.png?raw=true" alt="">
	</div>


	
    <p>In our previous work, we parametrized the flat output $ {\sigma}$ directly as a piecewise polynomial function of time. 
	    While this method is efficient and straightforward, Eq. (\ref{eq:phi0}) and Eq. (\ref{eq:omega0}) face singularities when the robot's velocity $\dot{ {\sigma}}_{|t}$ is zero. 
	    This led to numerical instability in the optimization process, making it difficult to guarantee strict satisfaction of constraints. By contrast, 
	    in this paper, we intuitively introduce a <i>Pseudo Arc</i> parametrized in the same piece-wise polynomial fashion.
	By indirectly deriving the state variables using the flat model, this approach fundamentally eradicates the singularity issues:
	\begin{align}
	 {\sigma} = {\gamma}(s),s = s(t). 
	\end{align}
	Here, $s\in\mathbb{R}^+$ is the<i>Pseudo Arc</i> and
	we refer to this indirect trajectory representation method as the Dual-Layer Polynomial-Based parametrization. 
	Then the finite-dimensional derivative of the flat output can also be derived as follows:

	\begin{align}
	\dot{ {\sigma}}_{|t}	& =  \dot{ {\gamma}}_{|s} \dot{s}_{|t},\label{eq:sigma}
    	\end{align}	
	    
    	\begin{align}
	\ddot{ {\sigma}}_{|t}	& =  \dot{ {\gamma}}_{|s} \ddot{s}_{|t} + \dot{s}_{|t}^2\ddot{ {\gamma}}_{|s},\label{eq:dsigma}
    	\end{align}	

	 \begin{align}   
	\dddot{ {\sigma}}_{|t}	&=
	\dddot{s}_{|t}\dot{ {\gamma}}_{|s} + 3\dot{s}_{|t}\ddot{ {\gamma}}_{|s}\ddot{s}_{|t}+\dot{s}_{|t}^3\dddot{ {\gamma}}_{|s},\label{eq:ddsigma}
	\end{align}</p>

	<p>$\dot{ {\gamma}}_{|s}, \ddot{ {\gamma}}_{|s}$ and $ \dddot{ {\gamma}}_{|s}$
	are the  first, second, and third derivatives of the flat output w.r.t <i>Pseudo Arc</i>, respectively.
	It is worth mentioning that $\dot{ {\sigma}}_{|t}$ represents the actual motion velocity of the robot, while $\dot{ {\gamma}}_{|s}$ is defined as the <i>Pseudo Arc</i>.
	Moreover, the physical meaning of $\dot{s}_{|t}\geq0$ is the magnitude of velocity along the <i>Pseudo Arc</i>.
	We substitute Eq. (\ref{eq:sigma}-\ref{eq:ddsigma}) into Eq. (\ref{eq:v0}-\ref{eq:omega0}), thus modifying the differential flatness model as follows:

		\begin{align}
		v(t)     & =  \eta ||\dot{ {\gamma}}_{|s}||_2 \dot{s}_{|t},  
		\theta    =   \arctan2(\eta\dot{\gamma}_{y|s}, \eta\dot{\gamma}_{x|s}), \label{eq:v1}
		\end{align}

		\begin{align}
		a(t)  & =  \eta(\ddot{s}_{|t}||\dot{ {\gamma}}_{|s}||_2+	\frac{\dot{s}_{|t}^2\ddot{ {\gamma}}_{|s}^\mathrm{T}\dot{ {\gamma}}_{|s}}{||\dot{ {\gamma}}_{|s}||_2}),\label{eq:at1}
		\end{align}

		\begin{align}
		\phi(t)   & =   \arctan\left(\eta\frac{\ddot{ {\gamma}}_{|s}^\mathrm{T}  {{\rm B}} \dot{ {\gamma}}_{|s}L   }{ {||\dot{ {\gamma}}_{|s}||}_2^3}\right),
		\end{align}

		\begin{align}
		\omega(t) &= \eta L \frac{  \dddot{ {\gamma}}_{|s}^\mathrm{T} {{\rm B}}\dot{ {\gamma}}_{|s}
			||\dot{ {\gamma}}_{|s}||_2^3-3\ddot{ {\gamma}}_{|s}^\mathrm{T} {{\rm B}}\dot{ {\gamma}}_{|s}\ddot{ {\gamma}}_{|s}^\mathrm{T}\dot{ {\gamma}}_{|s}||\dot{ {\gamma}}_{|s}||_2}{||\dot{ {\gamma}}_{|s}||_2^6+
			(\ddot{ {\gamma}}_{|s}^\mathrm{T} {{\rm B}}\dot{ {\gamma}}_{|s}L)^2}\dot{s}_{|t}.\label{eq:omega1}
		\end{align}</p>


	<p>When the robot's velocity is zero, we can set $\dot{s}_{|t}$ to zero while keeping <i>Pseudo Velocity</i> $\dot{ {\gamma}}_{|s}$ non-zero. In other words, in principle, 
		even during the transition between forward and backward motion states with zero velocity, we can ensure that $\dot{ {\gamma}}_{|s}$ remains non-zero. Consequently, 
		the denominator of Eq. (\ref{eq:at1}-\ref{eq:omega1})  are strictly positive, 
		eliminating the original singularity point. Next, we provide a detailed exposition of the parametric form of $ {\sigma}(t) = {\gamma}(s(t))$ based on dual-layer piece-wise polynomials.</p>

	

	<div class="center">
	<img  width="640" height="320" src="https://github.com/mengze3/mengze3.github.io/blob/6283c629a1581614069793aa089605617c92e3b5/_pages/seg.png?raw=true" alt="">
	</div>

	
	<p>Based on the front-end output, we first segment the trajectory according to the forward and backward modes.
	The $i$-th trajectory segment $ {\gamma}_i(s)$ is formulated as a $M_i$-piece polynomial with degree $D = 2u-1$, 
		which is parameterized by  the <i>Pseudo Arc</i> $\delta {{s}}_i = \left(\delta s_{i,1},...,\delta s_{i,M_i} \right)^{\rm T}\in  \mathbb{R}^{M_i}
	$ corresponding to each piece and the coefficient matrix $ {{c}}^p_i =https://github.com/mengze3/mengze3.github.io/blob/6283c629a1581614069793aa089605617c92e3b5/_pages/car.png \left({( {{c}}_{i,1}^p)}^{\rm T} ,... , {( {{ c}}_{i,M_i}^p)}^{\rm T} \right)^{\rm T}\in  \mathbb{R}^{2M_iu\times 2}$.
	Similarly, the $i$-th <i>Pseudo Arc</i> $s_i(t)$ is represented as a one-dimensional and time-uniform  $M_i$-piece polynomial, 
		parameterized by the time interval for each piece $\delta T_i$ and coefficient matrix $ {{c}}^s_i = \left({( {{c}}_{i,1}^s)}^{\rm T} ,... , {( {{ c}}_{i,M_i}^s)}^{\rm T} \right)^{\rm T}\in  \mathbb{R}^{2M_iu}$. 
		Moreover, we consider a strict correspondence between each piece of the dual-layer piece-wise polynomials, such that for every time interval $\delta T_i$, the robot should traverse the corresponding <i>Pseudo Arc</i>:
	\begin{equation}
	\begin{aligned}
	s_i&(j*\delta T_i) = \sum_{o=1}^{j}\delta s_{i,o},\\
	\forall i & \in \{1,2,...,n\}, \forall j \in \{1,2,3,...,M_i\},\label{eq:cors}
	\end{aligned}
	\end{equation}
	where $n$ is the number of trajectory segments.</p>

	<p>Based on the above modeling, the $j$-th piece  of the $i$-th segment $ {\gamma}_{i,j}$ is represented as:
	\begin{equation}
	\begin{aligned}
	 {\gamma}_{i,j}(s_{i,j}) &:=  {( {{ c}}_{i,j}^p)}^{\rm T}  {\beta}(s_{i,j} - \sum_{o=1}^{j-1}\delta s_{i,o}),\\ 
	s_{i,j}(t) &:= {( {{ c}}_{i,j}^s)}^{\rm T}  {\beta}(t),\forall  t \in [0, \delta T_i],\\
	 {\beta}(x) &:= \left(1, x, x^2, ..., x^N\right)^{\rm T},  
	\\ \forall i & \in \{1,2,...,n\}, \forall j \in \{1,2,3,...,M_i\}, \\
	\end{aligned}
	\end{equation}
	where $ {\beta}(x)$ is a natural basis function.
	Moreover, due to the strict correspondence between each piece of the dual-layer polynomials, we can further derive the following equation:
	\begin{equation}
	\begin{aligned}
	s_{i,j}(0) &:= \sum_{o=1}^{j-1}\delta s_{i,o}, s_{i,j}(\delta T_i) :=s_{i,j}(0)+ \delta s_{i,j},
	\\\forall i & \in \{1,2,...,n\}, \forall j \in \{1,2,3,...,M_i\}, \\
	\end{aligned}
	\end{equation}
	where $s_{i,1}(0)$ is set as $0$.
	Furturemore, the $M_i$-piece polynomial  $ {\gamma}_i$ is obtained:
	\begin{equation}
	\begin{aligned}
	 {\gamma}_i(s_i) = &  {\gamma}_{i,j} (s_i), 
	s_i(t) =  s_{i,j} (t-(j-1)*\delta T_i),\\
	\forall j \in& \{1,2,...,M_i\}, t \in [(j-1)*\delta T_i, j*\delta T_i).
	\end{aligned}
	\end{equation}</p>	


	<p>For brevity, we define the total duration of the $i$-th segment of the trajectory as $T_i = M_i * \delta T_i$.
	Then, the complete trajectory representation $ {\sigma}(t): [0,T_s]$ is formulated:
	\begin{equation}
	\begin{aligned}
	 {\sigma}(t) &=  {\gamma}_i(s_i (t-\sum_{k=1}^{i-1}T_i)),\\
	\forall i &\in \{1,2,...,n\},  t \in [\hat T_{i}, \hat T_{i+1}),  \\
	\end{aligned}
	\end{equation}
	where $T_s = \sum_{i=1}^{n}T_i$ represents the duration of the entire trajectory, $\hat T_i = \sum_{o=1}^{i-1} T_{o}$ denotes the timestamp of the starting point of the $i$-th segment, and $\hat T_1$ is set to 0. Moreover, for subsequent derivations, we define the sets of coefficient matrices for the dual-layer polynomials
	 $ {{\rm c}}^p=\left(( {{ c}}_1^p)^{\rm T},...,( {{c}}_n^p)^{\rm T}\right)^{\rm T} \in  \mathbb{R}^{\left(\sum_{i=1}^{n}2M_iu\right) \times 2}$,
	 $ {{\rm c}}^s=\left(( {{ c}}_1^s)^{\rm T},...,( {{c}}_n^s)^{\rm T}\right)^{\rm T} \in  \mathbb{R}^{\sum_{i=1}^{n}2M_iu }$,
	  the <i>Pseudo Arc</i> set
	  $\delta {{\rm s}}=\left(\delta {{s}}_1^{\rm T},...,\delta {{s}}_n^{\rm T}\right)^{\rm T} \in  \mathbb{R}^{\sum_{i=1}^{n}M_i}$,
	  , and the time set  
	  %$\delta {{\rm T}}=\left(\delta{T}_1,...,\delta{T}_n\right)^{\rm T} \in  \mathbb{R}^{n}$.
	$ {{\rm T}}=\left({T}_1,...,{T}_n\right)^{\rm T} \in  \mathbb{R}^{n}$.
	With motion feasibility constraints, the minimum  control effort problem
	 based on the modified flatness model Eq. (\ref{eq:v1}-\ref{eq:omega1}),
	 incorporating first-order temporal regularization, is formulated as a nonlinear constrained optimization:</p>	


	<p>
	\begin{align}
	\min_{ {{\rm c}}^p, {{\rm c}}^s,\delta {{\rm s}}, {{\rm T}} } J({ {{\rm c}}^p, {{\rm c}}^s,\delta {{\rm s}}, {{\rm T}} }) = \int_{0}^{T_s}  {\sigma}^{(u)}(t)^{\rm T}  {\sigma}^{(u)}(t)dt + \rho T_s   \label{eq:originopt}
	\end{align}
	\setlength\abovedisplayskip{0.1pt}
	\begin{align}
	{\rm s.t.} 	
	&\mathcal{B}_{ini}( {\sigma}(0),..., {\sigma}^{(u-1)}(0)) = 0, \label{eq:initial_boundary}
	\end{align}

	
	\begin{align}
	&\mathcal{B}_{fin}( {\sigma}(T_s),..., {\sigma}^{(u-1)}(T_s)) = 0, \label{eq:final_boundary}
	\end{align}

	\begin{align}
	& {\gamma}^{[\widetilde d]}_{i,j}(\sum_{k=1}^{j} \delta s_{i,k}) =  {\gamma}^{[\widetilde d]}_{i,j+1}(\sum_{k=1}^{j} \delta s_{i,k}), \label{eq:continuityrs} 
	\end{align}

	\begin{align}
	&s^{[\widetilde d]}_{i,j}(\delta T_i) = s^{[\widetilde d]}_{i,j+1}(0), \label{eq:continuityscale}
	\end{align}

	\begin{align}
	&T_i > 0,  \label{eq:temporal}  
	\end{align}
		
	\begin{align}
	&||\dot{ {\gamma}}_{i|s}(s_i(t))||_2 > \alpha,  \label{eq:mini vel}
	\end{align}

	\begin{align}
	&s_i^{(1)}(t) \geq 0, \forall t \in [0, T_i], \label{eq:scale}
	\end{align}

	\begin{align}
	&\mathcal{G}( {\gamma}_i(s_i(t)), ..., {\gamma}_{i|s}^{(u)}(s_i(t)),
	s_i(t),...,	s_{i|t}^{(u)}(t)
	 )\preceq 0,    \label{eq:user}
	\end{align}

	\begin{align}
	&\forall i \in \{1,...,n\}, \forall j \in \{1,...,M_i-1\},\forall t \in [0, T_i].\label{eq:originopt1}
	\end{align}

	$u=3$ is the control dimension and $\rho\in \mathbb{R}^+$ is a user-defined weight for
	the time regularization term to restrict the total duration $T_s$. Eq. (\ref{eq:initial_boundary}) and Eq. (\ref{eq:final_boundary}) represent the initial and final state constraints of the trajectory, 
	respectively. Eq. (\ref{eq:continuityrs})(\ref{eq:continuityscale}) denotes the continuity constraints up to degree $\widetilde{d}$ at the junctions of the piece-wise 
	polynomials. Eq. (\ref{eq:temporal}) and Eq. (\ref{eq:scale}) correspond to positive-definite constraints on time and \textit{Pseudo Velocity}, respectively. Eq. (\ref{eq:mini vel}) is a minimum
	\textit{Pseudo Velocity} constraint introduced to avoid singularities, where $\alpha$ is a threshold value. $\mathcal{G}$ encompasses common inequality constraints considered in trajectory planning problems, 
	including dynamic feasibility and obstacle avoidance constraints, the specific forms of which can be found in our previous work.</p>	
    

	<h1>EVALUATIONS</h1>

	<div class="center">
		<img  width="480" height="260" src="https://github.com/mengze3/mengze3.github.io/blob/2688bd2070568c2b380389edb19bc12ac34a7b8a/_pages/bench1.png?raw=true" alt="">
	</div>



	<div class="center">
		<img  width="480" height="260" src="https://github.com/mengze3/mengze3.github.io/blob/2688bd2070568c2b380389edb19bc12ac34a7b8a/_pages/bench2.png?raw=true" alt="">
	</div>
	
</body>
